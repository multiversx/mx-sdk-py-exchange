{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydoc import doc\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from multiversx_sdk import ApiNetworkProvider, ProxyNetworkProvider\n",
    "from multiversx_sdk.abi import Abi\n",
    "import os\n",
    "import importlib\n",
    "from argparse import Namespace\n",
    "from time import sleep\n",
    "import pprint\n",
    "\n",
    "os.environ[\"MX_DEX_ENV\"] = \"chainsim\"\n",
    "os.environ[\"LOG_LEVEL\"] = \"INFO\"\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent.absolute()))\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from context import Context\n",
    "from utils.utils_chain import WrapperAddress, Account\n",
    "from utils.utils_generic import get_logger\n",
    "from tools.chain_simulator_connector import ChainSimulator, start_handler\n",
    "from contracts.metastaking_contract import MetaStakingContract\n",
    "from contracts.farm_contract import FarmContract\n",
    "from contracts.staking_contract import StakingContract\n",
    "from utils.utils_scenarios import PhaseDictsCollector\n",
    "\n",
    "docker_path = config.HOME / \"Projects/testing/full-stack-docker-compose/chain-simulator\"\n",
    "chain_sim = ChainSimulator(docker_path)\n",
    "\n",
    "logger = get_logger(\"farm-timestamps\")\n",
    "\n",
    "if config.CURRENT_ENV.value == \"chainsim\":\n",
    "    global found_accounts\n",
    "    found_accounts = []\n",
    "    if not chain_sim.is_running():\n",
    "        state_path = config.DEFAULT_WORKSPACE / \"states\"\n",
    "        args = Namespace(docker_path=str(docker_path), state_path=str(state_path))\n",
    "        chain_sim, found_accounts = start_handler(args)\n",
    "        print(f'Loaded {len(found_accounts)} accounts')\n",
    "\n",
    "context = Context()\n",
    "\n",
    "FARM_BYTECODE_PATH = config.HOME / \"Projects/dex/mx-exchange-sc/output-docker/farm-with-locked-rewards/farm-with-locked-rewards.wasm\"\n",
    "FARM_EXPECTED_CODEHASH = \"2dc81c4dc7981ee14a8e86fca9f466172d5df6c62e849a270fe7c3dc8572988a\"\n",
    "\n",
    "STAKING_BYTECODE_PATH = config.HOME / \"Projects/dex/mx-exchange-sc/output-docker/farm-staking/farm-staking.wasm\"\n",
    "STAKING_EXPECTED_CODEHASH = \"eeb701f2b8a7e8ffddef36939f9e7149e14c72b766d75855cdb23caab0097c5e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastaking_contract: MetaStakingContract = context.deploy_structure.get_deployed_contract_by_index(config.METASTAKINGS_BOOSTED, 0)\n",
    "farm_contract: FarmContract = context.deploy_structure.get_deployed_contract_by_address(config.FARMS_V2, metastaking_contract.farm_address)\n",
    "staking_contract: StakingContract = context.deploy_structure.get_deployed_contract_by_address(config.STAKINGS_V2, metastaking_contract.stake_address)\n",
    "\n",
    "print(f\"Using {metastaking_contract.address} : {metastaking_contract.metastake_token}\")\n",
    "pprint.pprint(metastaking_contract.get_config_dict())\n",
    "pprint.pprint(staking_contract.get_config_dict())\n",
    "pprint.pprint(farm_contract.get_config_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_scenarios import collect_farm_contract_users, FetchedUser\n",
    "from typing import List\n",
    "\n",
    "def collect_users_for_contract(contract_address: str, farming_token: str, farm_token: str, proxy: ProxyNetworkProvider) -> List[FetchedUser]:\n",
    "    mainnet_api = ApiNetworkProvider(\"https://api.multiversx.com\")\n",
    "    SEARCH_BATCH_SIZE = 100\n",
    "    fetched_users = collect_farm_contract_users(SEARCH_BATCH_SIZE, contract_address, farming_token, farm_token,\n",
    "                                                mainnet_api, proxy)\n",
    "\n",
    "    users: List[FetchedUser] = fetched_users.get_users_with_farm_tokens()\n",
    "    fetch_attempts = 0\n",
    "    while not users and fetch_attempts < 5:\n",
    "        fetched_users = collect_farm_contract_users(SEARCH_BATCH_SIZE, contract_address, farming_token, farm_token,\n",
    "                                                    mainnet_api, proxy, fetch_attempts * SEARCH_BATCH_SIZE)\n",
    "        users: List[FetchedUser] = fetched_users.get_users_with_farm_tokens()\n",
    "        fetch_attempts += 1\n",
    "    if not users:\n",
    "        logger.warning(f\"No users found with both tokens for {contract_address}\")\n",
    "        return fetched_users.get_users_with_farm_tokens()\n",
    "    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAIN SIM RESTART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = config.DEFAULT_WORKSPACE / \"states\"\n",
    "args = Namespace(docker_path=str(docker_path), state_path=str(state_path))\n",
    "chain_sim, found_accounts = start_handler(args)\n",
    "print(f'Loaded {len(found_accounts)} accounts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAIN CONFIG STATE RETRIEVE - ONE TIME ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.chain_simulator_connector import retrieve_handler\n",
    "\n",
    "retrieve_gateway = ProxyNetworkProvider(\"https://proxy-shadowfork-four.elrond.ro\")\n",
    "\n",
    "collected_users = collect_users_for_contract(metastaking_contract.address, metastaking_contract.farm_token, metastaking_contract.metastake_token, retrieve_gateway)\n",
    "if not collected_users:\n",
    "    raise Exception(\"No users found with both tokens\")\n",
    "\n",
    "for user in collected_users:\n",
    "    args = Namespace(gateway=retrieve_gateway.url, account=user.address.bech32())\n",
    "    retrieve_handler(args)\n",
    "\n",
    "print(\"Restart chain simulator to load the new state!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAIN CONFIG SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "from utils.utils_chain import WrapperAddress\n",
    "\n",
    "def chain_sim_init():\n",
    "    state_path = config.DEFAULT_WORKSPACE / \"states\"\n",
    "    args = Namespace(docker_path=str(docker_path), state_path=str(state_path))\n",
    "    chain_sim, found_accounts = start_handler(args)\n",
    "    print(f'Loaded {len(found_accounts)} accounts')\n",
    "    return chain_sim, found_accounts\n",
    "\n",
    "def advance_blocks(number_of_blocks: int):\n",
    "    chain_sim.advance_blocks(number_of_blocks)\n",
    "\n",
    "def advance_epoch(number_of_epochs: int):\n",
    "    chain_sim.advance_epochs(number_of_epochs)\n",
    "\n",
    "\n",
    "def users_init() -> list[Account]:\n",
    "    print(context.deployer_account.address.bech32())\n",
    "    context.deployer_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    users = []\n",
    "    for user in found_accounts:\n",
    "        if user == context.deployer_account.address.bech32():   # skip deployer account\n",
    "            continue\n",
    "        user_account = Account(pem_file=config.DEFAULT_ACCOUNTS)\n",
    "        user_account.address = WrapperAddress(user)\n",
    "        if user_account.address.get_shard() != 1:   # select only shard 1 accounts due to limitation in system account token attributes retrieval\n",
    "            continue\n",
    "        user_account.sync_nonce(context.network_provider.proxy)\n",
    "        users.append(user_account)\n",
    "\n",
    "    return users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAIN SIMULATOR STACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from time import sleep\n",
    "\n",
    "CS_DOCKER_PATH = Path.home() / \"projects/testing/full-stack-docker-compose/chain-simulator\"\n",
    "\n",
    "def start_chain_sim_stack():\n",
    "    # stop first in case one is already running\n",
    "    p = subprocess.Popen([\"docker\", \"compose\", \"down\"], cwd = CS_DOCKER_PATH)\n",
    "    p.wait()\n",
    "    \n",
    "    p = subprocess.Popen([\"docker\", \"compose\", \"up\", \"-d\"], cwd = CS_DOCKER_PATH)\n",
    "    sleep(60)\n",
    "    return p\n",
    "\n",
    "def stop_chain_sim_stack(p):\n",
    "    p.terminate()\n",
    "    p = subprocess.Popen([\"docker\", \"compose\", \"down\"], cwd = CS_DOCKER_PATH)\n",
    "    p.wait()\n",
    "    _ = subprocess.run([\"docker\", \"system\", \"prune\", \"-f\"], cwd = CS_DOCKER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farm upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farm_upgrade(assert_code_hash: bool = True):\n",
    "    tx_hash = farm_contract.contract_upgrade(context.deployer_account, context.network_provider.proxy, \n",
    "                                            FARM_BYTECODE_PATH, \n",
    "                                            [], True)\n",
    "\n",
    "    # advance_blocks(1)\n",
    "    tx_hash = farm_contract.resume(context.deployer_account, context.network_provider.proxy)\n",
    "    # advance_blocks(1)\n",
    "\n",
    "    if assert_code_hash:\n",
    "        code_hash = context.network_provider.proxy.get_account(WrapperAddress(farm_contract.address)).contract_code_hash.hex()\n",
    "        assert code_hash == FARM_EXPECTED_CODEHASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metastaking upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metastaking_upgrade():\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Staking upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staking_upgrade(assert_code_hash: bool = True):\n",
    "    tx_hash = staking_contract.contract_upgrade(context.deployer_account, context.network_provider.proxy, \n",
    "                                                STAKING_BYTECODE_PATH,\n",
    "                                                [], True)\n",
    "\n",
    "    # advance_blocks(1)\n",
    "    tx_hash = staking_contract.resume(context.deployer_account, context.network_provider.proxy)\n",
    "    # advance_blocks(1)\n",
    "\n",
    "    if assert_code_hash:\n",
    "        code_hash = context.network_provider.proxy.get_account(WrapperAddress(staking_contract.address)).contract_code_hash.hex()\n",
    "        assert code_hash == STAKING_EXPECTED_CODEHASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy permissions hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contracts.permissions_hub_contract import PermissionsHubContract\n",
    "\n",
    "def deploy_permissions_hub():\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contracts.dummy_proxy_contract import DummyProxyContract\n",
    "\n",
    "def deploy_dummy_proxy_contract():\n",
    "    dummy_proxy_contract = DummyProxyContract(\"\")\n",
    "    _, address = dummy_proxy_contract.contract_deploy(context.deployer_account, context.network_provider.proxy,\n",
    "                                         \"https://github.com/ovidiuolteanu/mx-sc-dummy-proxy/releases/download/v2.1/dummy-proxy.wasm\",\n",
    "                                         [])\n",
    "    dummy_proxy_contract.address = address\n",
    "    return dummy_proxy_contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import get_all_token_nonces_details_for_account\n",
    "\n",
    "def get_position_for_account(user_address: str):\n",
    "    metastake_tk_balance, metastake_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, user_address, context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} positions of {metastaking_contract.metastake_token} in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > metastake_tk_balance:\n",
    "            metastake_tk_balance = int(token['balance'])\n",
    "            metastake_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not metastake_tk_nonce:\n",
    "        raise Exception(\"Not enough metastake token balance\")\n",
    "    \n",
    "    return metastake_tk_nonce, metastake_tk_balance\n",
    "\n",
    "def get_farming_position_for_account(user_address: str):\n",
    "    farm_tk_balance, farm_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(farm_contract.farmToken, user_address, context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} positions of {farm_contract.farmToken} in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farm_tk_balance:\n",
    "            farm_tk_balance = int(token['balance'])\n",
    "            farm_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farm_tk_nonce:\n",
    "        raise Exception(\"Not enough farm token balance\")\n",
    "    \n",
    "    return farm_tk_nonce, farm_tk_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_tx import ESDTToken, multi_esdt_transfer\n",
    "\n",
    "def send_tokens_to_dummy(user: Account, dummy_contract: DummyProxyContract):\n",
    "    farm_tk_nonce, farm_tk_balance = get_position_for_account(user)\n",
    "    print(f\"Sending {farm_tk_balance} {metastaking_contract.metastake_token}-{farm_tk_nonce} to dummy contract\")\n",
    "    multi_esdt_transfer(context.network_provider.proxy, 20000000, user, dummy_contract.address, [ESDTToken(metastaking_contract.metastake_token, farm_tk_nonce, farm_tk_balance)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import Account, WrapperAddress as Address, get_all_token_nonces_details_for_account\n",
    "\n",
    "def claim_for_user(user_account: Account):\n",
    "    user_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    farm_tk_balance, farm_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, user_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} positions of {metastaking_contract.metastake_token} in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farm_tk_balance:\n",
    "            farm_tk_balance = int(token['balance'])\n",
    "            farm_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farm_tk_nonce:\n",
    "        raise Exception(\"Not enough metastake token balance\")\n",
    "    \n",
    "    tokens = [ESDTToken(metastaking_contract.metastake_token, farm_tk_nonce, farm_tk_balance)]\n",
    "\n",
    "    tx_hash = metastaking_contract.claim_rewards_metastaking(context.network_provider.proxy, user_account, [tokens])\n",
    "    return tx_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim on behalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import Account, WrapperAddress as Address, get_all_token_nonces_details_for_account\n",
    "\n",
    "def claim_on_behalf_from_user(claim_account: Account):\n",
    "    claim_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    farm_tk_balance, farm_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, claim_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} positions of {metastaking_contract.metastake_token} in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farm_tk_balance:\n",
    "            farm_tk_balance = int(token['balance'])\n",
    "            farm_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farm_tk_nonce:\n",
    "        raise Exception(\"Not enough farm token balance\")\n",
    "    \n",
    "    tokens = [ESDTToken(metastaking_contract.metastake_token, farm_tk_nonce, farm_tk_balance)]\n",
    "\n",
    "    tx_hash = metastaking_contract.claim_rewards_on_behalf_metastaking(context.network_provider.proxy, claim_account, [tokens])\n",
    "    return tx_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter farm consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import Account, WrapperAddress as Address, get_all_token_nonces_details_for_account\n",
    "\n",
    "def enter_farm_for_user(user_account: Account):\n",
    "    user_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    farming_tk_balance, farming_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.farm_token, user_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} farming tokens in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farming_tk_balance:\n",
    "            farming_tk_balance = int(token['balance'])\n",
    "            farming_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farming_tk_balance:\n",
    "        raise Exception(\"Not enough farming token balance\")\n",
    "    \n",
    "    tokens = [ESDTToken(metastaking_contract.farm_token, farming_tk_nonce, farming_tk_balance)]\n",
    "\n",
    "    farm_tk_balance, farm_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, user_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} positions of {metastaking_contract.metastake_token} in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farm_tk_balance:\n",
    "            farm_tk_balance = int(token['balance'])\n",
    "            farm_tk_nonce = token['nonce']\n",
    "            \n",
    "            tokens.append(ESDTToken(metastaking_contract.metastake_token, farm_tk_nonce, farm_tk_balance))\n",
    "\n",
    "    if not farm_tk_nonce:\n",
    "        raise Exception(\"Not enough farm token balance\")\n",
    "\n",
    "    tx_hash = metastaking_contract.enter_metastake(context.network_provider.proxy, user_account, [tokens])\n",
    "    return tx_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter farm no consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import Account, WrapperAddress as Address, get_all_token_nonces_details_for_account\n",
    "\n",
    "def enter_farm_no_consolidation_for_user(user_account: Account):\n",
    "    user_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    farming_tk_balance, farming_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.farm_token, user_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} farming tokens in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farming_tk_balance:\n",
    "            farming_tk_balance = int(token['balance'])\n",
    "            farming_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farming_tk_balance:\n",
    "        raise Exception(\"Not enough farming token balance\")\n",
    "\n",
    "    tokens = [ESDTToken(metastaking_contract.farm_token, farming_tk_nonce, farming_tk_balance)]\n",
    "    tx_hash = metastaking_contract.enter_metastake(context.network_provider.proxy, user_account, [tokens])\n",
    "    return tx_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter farm on behalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import Account, WrapperAddress as Address, get_all_token_nonces_details_for_account\n",
    "\n",
    "def enter_farm_on_behalf_for_user(caller_account: Account, user_account: Account):\n",
    "    caller_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    farming_tk_balance, farming_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.farm_token, caller_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} farming tokens in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farming_tk_balance:\n",
    "            farming_tk_balance = int(token['balance'])\n",
    "            farming_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farming_tk_balance:\n",
    "        raise Exception(\"Not enough farming token balance\")\n",
    "    \n",
    "    tokens = [ESDTToken(metastaking_contract.farm_token, farming_tk_nonce, farming_tk_balance)]\n",
    "\n",
    "    farm_tk_balance, farm_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, caller_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} positions of {metastaking_contract.metastake_token} in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farm_tk_balance:\n",
    "            farm_tk_balance = int(token['balance'])\n",
    "            farm_tk_nonce = token['nonce']\n",
    "            \n",
    "            tokens.append(ESDTToken(metastaking_contract.metastake_token, farm_tk_nonce, farm_tk_balance))\n",
    "\n",
    "    if not farm_tk_nonce:\n",
    "        raise Exception(\"Not enough farm token balance\")\n",
    "\n",
    "    tx_hash = metastaking_contract.enter_metastake_on_behalf(context.network_provider.proxy, caller_account, [tokens, user_account.address.bech32()])\n",
    "    return tx_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter farm on behalf no consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import Account, WrapperAddress as Address, get_all_token_nonces_details_for_account\n",
    "\n",
    "def enter_farm_on_behalf_no_consolidation_for_user(caller_account: Account, user_account: Account):\n",
    "    caller_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    farming_tk_balance, farming_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.farm_token, caller_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} farming tokens in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farming_tk_balance:\n",
    "            farming_tk_balance = int(token['balance'])\n",
    "            farming_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farming_tk_balance:\n",
    "        raise Exception(\"Not enough farming token balance\")\n",
    "\n",
    "    tokens = [ESDTToken(metastaking_contract.farm_token, farming_tk_nonce, farming_tk_balance)]\n",
    "\n",
    "    tx_hash = metastaking_contract.enter_metastake_on_behalf(context.network_provider.proxy, caller_account, [tokens, user_account.address.bech32()])\n",
    "    return tx_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exit farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_chain import Account, WrapperAddress as Address, get_all_token_nonces_details_for_account\n",
    "\n",
    "def exit_for_user(user_account: Account):\n",
    "    user_account.sync_nonce(context.network_provider.proxy)\n",
    "\n",
    "    farm_tk_balance, farm_tk_nonce = 0, 0\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, user_account.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Found {len(tokens_in_account)} positions of {metastaking_contract.metastake_token} in account')\n",
    "    for token in tokens_in_account:\n",
    "        if int(token['balance']) > farm_tk_balance:\n",
    "            farm_tk_balance = int(token['balance'])\n",
    "            farm_tk_nonce = token['nonce']\n",
    "            break\n",
    "\n",
    "    if not farm_tk_nonce:\n",
    "        raise Exception(\"Not enough metastake token balance\")\n",
    "    \n",
    "    tokens = [ESDTToken(metastaking_contract.metastake_token, farm_tk_nonce, farm_tk_balance)]\n",
    "\n",
    "    tx_hash = metastaking_contract.exit_metastake(context.network_provider.proxy, user_account, [tokens, 1, 1])\n",
    "    return tx_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_data():\n",
    "    raw_data = context.network_provider.proxy.get_network_status(1)\n",
    "    return {\n",
    "        \"current_epoch\": raw_data.current_epoch,\n",
    "        \"current_round\": raw_data.current_round,\n",
    "        \"current_block\": raw_data.block_nonce,\n",
    "        \"current_block_timestamp\": raw_data.block_timestamp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.decoding_structures import METASTAKE_TOKEN_ATTRIBUTES\n",
    "from utils.utils_chain import decode_merged_attributes, base64_to_hex, WrapperAddress, get_all_token_nonces_details_for_account\n",
    "\n",
    "def user_farm_token_stats(user: Account):\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.farm_token, user.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Account: {user.address.bech32()}')\n",
    "    print(f'Looking for {metastaking_contract.farm_token} and {metastaking_contract.metastake_token} tokens')\n",
    "    print(f'Farming Tokens in account:')\n",
    "    for token in tokens_in_account:\n",
    "        print(f'\\t{token}')\n",
    "    tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, user.address.bech32(), context.network_provider.proxy)\n",
    "    print(f'Farm Tokens in account:')\n",
    "    all_decoded_attributes = []\n",
    "    for token in tokens_in_account:\n",
    "        print(f'\\t{token}')\n",
    "        decoded_attributes = metastaking_contract.get_all_decoded_metastake_token_attributes_from_proxy(context.network_provider.proxy, user.address.bech32(), token['nonce'])\n",
    "        print(f'\\t\\t{decoded_attributes}')\n",
    "        all_decoded_attributes.append(decoded_attributes)\n",
    "        \n",
    "    return all_decoded_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum, auto\n",
    "from collections import defaultdict\n",
    "\n",
    "class DictType(Enum):\n",
    "    USER_FARM_STATS_1 = auto()\n",
    "    USER_STAKING_STATS_1 = auto()\n",
    "    USER_2_FARM_STATS_1 = auto()\n",
    "    USER_2_STAKING_STATS_1 = auto()\n",
    "    PROXY_FARM_STATS_1 = auto()\n",
    "    PROXY_STAKING_STATS_1 = auto()\n",
    "    FARM_CONTRACT_STATS_1 = auto()\n",
    "    STAKING_CONTRACT_STATS_1 = auto()\n",
    "    TOKEN_ATTRS_1 = auto()\n",
    "    USER_FARM_STATS_2 = auto()\n",
    "    USER_STAKING_STATS_2 = auto()\n",
    "    USER_2_FARM_STATS_2 = auto()\n",
    "    USER_2_STAKING_STATS_2 = auto()\n",
    "    PROXY_FARM_STATS_2 = auto()\n",
    "    PROXY_STAKING_STATS_2 = auto()\n",
    "    FARM_CONTRACT_STATS_2 = auto()\n",
    "    STAKING_CONTRACT_STATS_2 = auto()\n",
    "    TOKEN_ATTRS_2 = auto()\n",
    "    OP1 = auto()\n",
    "    OP2 = auto()\n",
    "    OP3 = auto()\n",
    "    OP4 = auto()\n",
    "    OP5 = auto()\n",
    "\n",
    "@dataclass\n",
    "class DictComparison:\n",
    "    before: Dict[str, Any]\n",
    "    after: Dict[str, Any]\n",
    "    description: str\n",
    "    phase: str\n",
    "\n",
    "class DictCollector:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset all collections for a new scenario\"\"\"\n",
    "        self.before_upgrade: Dict[DictType, List[Tuple[Dict[str, Any], str]]] = defaultdict(list)\n",
    "        self.after_upgrade: Dict[DictType, List[Tuple[Dict[str, Any], str]]] = defaultdict(list)\n",
    "        self.current_phase = \"before\"  # \"before\" or \"after\"\n",
    "    \n",
    "    def set_phase(self, phase: str):\n",
    "        \"\"\"Set the current collection phase\"\"\"\n",
    "        if phase not in [\"before\", \"after\"]:\n",
    "            raise ValueError(\"Phase must be 'before' or 'after'\")\n",
    "        self.current_phase = phase\n",
    "\n",
    "    def add(self, dict_type: DictType, dict_data: Dict[str, Any], description: str = \"\"):\n",
    "        \"\"\"Add a dictionary to the current phase collection\"\"\"\n",
    "        if self.current_phase == \"before\":\n",
    "            self.before_upgrade[dict_type].append((dict_data, description))\n",
    "        else:\n",
    "            self.after_upgrade[dict_type].append((dict_data, description))\n",
    "\n",
    "    def _compare_dicts(self, dict1: Any, dict2: Any) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Compare two objects that can be either dictionaries or lists of dictionaries.\n",
    "        Returns (is_equal, difference_description)\n",
    "        \"\"\"\n",
    "        # Handle lists of dictionaries\n",
    "        if isinstance(dict1, list) and isinstance(dict2, list):\n",
    "            if len(dict1) != len(dict2):\n",
    "                return False, f\"Different list lengths: {len(dict1)} != {len(dict2)}\"\n",
    "            \n",
    "            for i, (item1, item2) in enumerate(zip(dict1, dict2)):\n",
    "                if isinstance(item1, (dict, list)) and isinstance(item2, (dict, list)):\n",
    "                    is_equal, diff = self._compare_dicts(item1, item2)\n",
    "                    if not is_equal:\n",
    "                        return False, f\"List item {i} difference: {diff}\"\n",
    "                elif item1 != item2:\n",
    "                    return False, f\"List item {i} mismatch: {item1} != {item2}\"\n",
    "            return True, None\n",
    "\n",
    "        # Handle dictionaries\n",
    "        if isinstance(dict1, dict) and isinstance(dict2, dict):\n",
    "            if dict1.keys() != dict2.keys():\n",
    "                missing_keys = set(dict1.keys()) - set(dict2.keys())\n",
    "                extra_keys = set(dict2.keys()) - set(dict1.keys())\n",
    "                return False, f\"Different keys. Missing: {missing_keys}, Extra: {extra_keys}\"\n",
    "\n",
    "            for key in dict1:\n",
    "                if isinstance(dict1[key], (dict, list)) and isinstance(dict2[key], (dict, list)):\n",
    "                    is_equal, diff = self._compare_dicts(dict1[key], dict2[key])\n",
    "                    if not is_equal:\n",
    "                        return False, f\"Nested difference at key '{key}': {diff}\"\n",
    "                elif dict1[key] != dict2[key]:\n",
    "                    return False, f\"Value mismatch for key '{key}': {dict1[key]} != {dict2[key]}\"\n",
    "            return True, None\n",
    "\n",
    "        # Handle case where types don't match\n",
    "        if type(dict1) != type(dict2):\n",
    "            return False, f\"Type mismatch: {type(dict1)} != {type(dict2)}\"\n",
    "\n",
    "        # Handle other cases\n",
    "        return dict1 == dict2, f\"Value mismatch: {dict1} != {dict2}\" if dict1 != dict2 else None\n",
    "\n",
    "    def compare_all(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Compare all collected dictionary pairs and return a list of differences found.\n",
    "        \"\"\"\n",
    "        differences = []\n",
    "\n",
    "        for dict_type in DictType:\n",
    "            before_list = self.before_upgrade[dict_type]\n",
    "            after_list = self.after_upgrade[dict_type]\n",
    "\n",
    "            # Check if we have matching pairs\n",
    "            if len(before_list) != len(after_list):\n",
    "                differences.append(\n",
    "                    f\"{dict_type.name}: Mismatched number of collections - \"\n",
    "                    f\"Before: {len(before_list)}, After: {len(after_list)}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Compare each pair\n",
    "            for i, ((before_dict, before_desc), (after_dict, after_desc)) in enumerate(zip(before_list, after_list)):\n",
    "                is_equal, diff = self._compare_dicts(before_dict, after_dict)\n",
    "                if not is_equal:\n",
    "                    diff_msg = f\"{dict_type.name} comparison failed\"\n",
    "                    if before_desc or after_desc:\n",
    "                        diff_msg += f\" (Before: {before_desc}, After: {after_desc})\"\n",
    "                    diff_msg += f\": {diff}\"\n",
    "                    differences.append(diff_msg)\n",
    "\n",
    "        return differences\n",
    "    \n",
    "    def print_collections(self):\n",
    "        \"\"\"\n",
    "        Print a formatted view of all collections before and after upgrade.\n",
    "        \"\"\"\n",
    "        print(\"\\nCollections Summary:\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for dict_type in DictType:            \n",
    "            before_list = self.before_upgrade[dict_type]\n",
    "            after_list = self.after_upgrade[dict_type]\n",
    "\n",
    "            if not before_list and not after_list:\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n{dict_type.name}:\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            print(\"\\nBefore upgrade:\")\n",
    "            if not before_list:\n",
    "                print(\"  No collections\")\n",
    "            for i, (data, desc) in enumerate(before_list, 1):\n",
    "                print(f\"  Collection {i}\" + (f\" ({desc})\" if desc else \"\"))\n",
    "                if isinstance(data, dict):\n",
    "                    for key, value in data.items():\n",
    "                        print(f\"    {key}: {value}\")\n",
    "                else:\n",
    "                    print(f\"    {data}\")\n",
    "\n",
    "            print(\"\\nAfter upgrade:\")\n",
    "            if not after_list:\n",
    "                print(\"  No collections\")\n",
    "            for i, (data, desc) in enumerate(after_list, 1):\n",
    "                print(f\"  Collection {i}\" + (f\" ({desc})\" if desc else \"\"))\n",
    "                if isinstance(data, dict):\n",
    "                    for key, value in data.items():\n",
    "                        print(f\"    {key}: {value}\")\n",
    "                else:\n",
    "                    print(f\"    {data}\")\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "collector = DictCollector()\n",
    "\n",
    "# Before upgrade\n",
    "collector.set_phase(\"before\")\n",
    "collector.add(DictType.USER_STATS, u1, \"Initial user stats\")\n",
    "collector.add(DictType.CONTRACT_STATS, c1, \"Initial contract stats\")\n",
    "collector.add(DictType.TOKEN_ATTRS, tk_attrs_1, \"Initial token attributes\")\n",
    "collector.add(DictType.CLAIM_OPS, claim_ops_1, \"Initial claim operations\")\n",
    "\n",
    "# After upgrade\n",
    "collector.set_phase(\"after\")\n",
    "collector.add(DictType.USER_STATS, u3, \"Post-upgrade user stats\")\n",
    "collector.add(DictType.CONTRACT_STATS, c3, \"Post-upgrade contract stats\")\n",
    "collector.add(DictType.TOKEN_ATTRS, tk_attrs_2, \"Post-upgrade token attributes\")\n",
    "collector.add(DictType.CLAIM_OPS, claim_ops_3, \"Post-upgrade claim operations\")\n",
    "\n",
    "# Compare results\n",
    "differences = collector.compare_all()\n",
    "if differences:\n",
    "    print(\"Found differences:\")\n",
    "    for diff in differences:\n",
    "        print(f\"- {diff}\")\n",
    "else:\n",
    "    print(\"All comparisons passed!\")\n",
    "\n",
    "# Alternatively, at the end of your test\n",
    "differences = collector.compare_all()\n",
    "assert not differences, \"\\n\".join(differences)\n",
    "\n",
    "# Reset for next scenario\n",
    "collector.reset()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_general_test_data(index: int,collector: PhaseDictsCollector, user: Account, farm_contract: FarmContract, staking_contract: StakingContract):\n",
    "    u1 = farm_contract.get_all_user_boosted_stats(user.address.bech32(), context.network_provider.proxy)\n",
    "    c1 = farm_contract.get_all_stats(context.network_provider.proxy)\n",
    "    su1 = staking_contract.get_all_user_boosted_stats(user.address.bech32(), context.network_provider.proxy)\n",
    "    s1 = staking_contract.get_all_stats(context.network_provider.proxy)\n",
    "    tk_attrs_1 = user_farm_token_stats(user)\n",
    "\n",
    "    collector.add(f\"USER_FARM_STATS_{index}\", u1, f\"Initial farm user stats\")\n",
    "    collector.add(f\"FARM_CONTRACT_STATS_{index}\", c1, f\"Initial farm contract stats\")\n",
    "    collector.add(f\"USER_STAKING_STATS_{index}\", su1, f\"Initial staking user stats\")\n",
    "    collector.add(f\"STAKING_CONTRACT_STATS_{index}\", s1, f\"Initial staking contract stats\")\n",
    "    collector.add(f\"TOKEN_ATTRS_{index}\", tk_attrs_1, f\"Initial token attributes\")\n",
    "\n",
    "def report_test_data(collector: PhaseDictsCollector, assert_no_differences: bool = True):\n",
    "    collector.print_collections()\n",
    "    \n",
    "    differences = collector.compare_all()\n",
    "    if differences:\n",
    "        print(\"Found differences:\")\n",
    "        for diff in differences:\n",
    "            print(f\"- {diff}\")\n",
    "    else:\n",
    "        print(\"All comparisons passed!\")\n",
    "        \n",
    "    if assert_no_differences:\n",
    "        assert not differences, \"\\n\".join(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "def get_transfered_tokens_to_user(collector: PhaseDictsCollector, user: Account, dict_type: str):\n",
    "    found_ops_before, found_ops_after = [], []\n",
    "    \n",
    "    def get_found_ops(container: list):\n",
    "        found_ops = []\n",
    "        for element in container:\n",
    "            search_dict = {\n",
    "                \"action\": \"transfer\",\n",
    "                \"sender\": metastaking_contract.address,\n",
    "                \"receiver\": user.address.bech32()\n",
    "            }\n",
    "            if all(item in element.items() for item in search_dict.items()):\n",
    "                found_ops.append(element)\n",
    "                # print(element)\n",
    "        return found_ops\n",
    "    \n",
    "    # found_ops_before = get_found_ops(collector.before_upgrade[dict_type][0][0])\n",
    "    # found_ops_after = get_found_ops(collector.after_upgrade[dict_type][0][0])\n",
    "    found_ops_before = get_found_ops(collector.collections[\"before\"][dict_type][0][0])\n",
    "    found_ops_after = get_found_ops(collector.collections[\"after\"][dict_type][0][0])\n",
    "    return found_ops_before, found_ops_after\n",
    "\n",
    "def compare_transfered_tokens_to_user(collector: PhaseDictsCollector, user: Account, dict_type: str):\n",
    "    logger.info(f\"Comparing for {dict_type}\")\n",
    "\n",
    "    found_ops_before, found_ops_after = get_transfered_tokens_to_user(collector, user, dict_type)\n",
    "\n",
    "    if len(found_ops_before) < 3:\n",
    "        logger.error(f\"Not enough operations found for {dict_type} before upgrade!\")\n",
    "    if len(found_ops_after) < 3:\n",
    "        logger.error(f\"Not enough operations found for {dict_type} after upgrade!\")\n",
    "        \n",
    "    for element in found_ops_before:\n",
    "        # remove value from element, then compare with after_upgrade[dict_type][0][0]\n",
    "        element_copy = deepcopy(element)\n",
    "        amount = int(element_copy.pop(\"value\"))\n",
    "        for after_element in found_ops_after:\n",
    "            if all(item in after_element.items() for item in element_copy.items()):\n",
    "                compared_amount = int(after_element.get(\"value\"))\n",
    "                if amount < compared_amount:\n",
    "                    logger.error(f\"TOO MUCH {after_element.get('identifier')}: Before upgrade amount {amount} is less than {compared_amount} after upgrade!\")\n",
    "                # if difference is more than 1%\n",
    "                elif abs(amount - compared_amount) / amount > 0.01:\n",
    "                    logger.error(f\"TOO LESS {after_element.get('identifier')}: Before upgrade amount {amount} is {abs(amount - compared_amount) / amount * 100}% different from {compared_amount} after upgrade!\")\n",
    "                else:\n",
    "                    logger.info(f\"OK {after_element.get('identifier')}: Before upgrade amount {amount} is {abs(amount - compared_amount) / amount * 100}% different from {compared_amount} after upgrade!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pre_update_test(initial_blocks: int) -> Tuple[Any, List[Account], PhaseDictsCollector]:\n",
    "    global found_accounts\n",
    "    chain_sim, found_accounts = chain_sim_init()\n",
    "\n",
    "    collector = PhaseDictsCollector()\n",
    "    collector.set_phase(\"before\")\n",
    "\n",
    "    users = users_init()\n",
    "    advance_blocks(3)\n",
    "    consumed_blocks = 3\n",
    "\n",
    "    collect_general_test_data(0, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{0}\", get_time_data(), \"Time data\")\n",
    "\n",
    "    advance_blocks(initial_blocks - consumed_blocks)\n",
    "\n",
    "    # collector = DictCollector()\n",
    "    # collector.set_phase(\"before\")\n",
    "\n",
    "    return chain_sim, users, collector\n",
    "\n",
    "def init_post_upgrade_test(initial_blocks: int, chain_sim: ChainSimulator, collector: PhaseDictsCollector):\n",
    "    # input(\"Restart Chain Simulator then press Enter to continue...\")\n",
    "    \n",
    "    chain_sim.stop()\n",
    "    chain_sim_init()\n",
    "\n",
    "    collector.set_phase(\"after\")\n",
    "    \n",
    "    users = users_init()\n",
    "    advance_blocks(1)\n",
    "    consumed_blocks = 1\n",
    "\n",
    "    farm_upgrade(False)  # eats 2 blocks\n",
    "    # consumed_blocks += 2\n",
    "    staking_upgrade(False)  # eats 2 blocks\n",
    "\n",
    "    advance_blocks(2)\n",
    "    consumed_blocks += 2\n",
    "\n",
    "    collect_general_test_data(0, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{0}\", get_time_data(), \"Time data\")\n",
    "\n",
    "    if initial_blocks < consumed_blocks:\n",
    "        raise Exception(f\"Initial blocks {initial_blocks} is less than consumed blocks {consumed_blocks}. Skewed results will occur.\")\n",
    "    \n",
    "    block_diff = initial_blocks - consumed_blocks\n",
    "    advance_blocks(block_diff)\n",
    "\n",
    "    return chain_sim, users\n",
    "\n",
    "def close_test(chain_sim: ChainSimulator, collector: PhaseDictsCollector, assert_no_differences: bool = True):\n",
    "    report_test_data(collector, assert_no_differences)\n",
    "    \n",
    "    print(\"Chain simulator need to be stopped manually...\")\n",
    "    # chain_sim.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_compare(d1, d2):\n",
    "    print(d1)\n",
    "    print(d2)\n",
    "    d1_keys = set(d1.keys())\n",
    "    d2_keys = set(d2.keys())\n",
    "    shared_keys = d1_keys.intersection(d2_keys)\n",
    "    added = d1_keys - d2_keys\n",
    "    removed = d2_keys - d1_keys\n",
    "    modified = {o : (d1[o], d2[o]) for o in shared_keys if d1[o] != d2[o]}\n",
    "    same = set(o for o in shared_keys if d1[o] == d2[o])\n",
    "    return added, removed, modified, same\n",
    "\n",
    "def check_equal_dicts(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Compare two dictionaries, including nested dictionaries.\n",
    "    \n",
    "    Args:\n",
    "    dict1 (dict): First dictionary to compare.\n",
    "    dict2 (dict): Second dictionary to compare.\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if dictionaries are equal, False otherwise.\n",
    "    \"\"\"\n",
    "    if dict1.keys() != dict2.keys():\n",
    "        return False\n",
    "    \n",
    "    for key in dict1:\n",
    "        if isinstance(dict1[key], dict) and isinstance(dict2[key], dict):\n",
    "            if not check_equal_dicts(dict1[key], dict2[key]):\n",
    "                return False\n",
    "        elif dict1[key] != dict2[key]:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_week_start_epoch(contract: FarmContract | StakingContract) -> int:\n",
    "    first_week = contract.get_first_week_start_epoch(context.network_provider.proxy)\n",
    "    current_week = contract.get_current_week(context.network_provider.proxy)\n",
    "    next_week_at_epoch = first_week + current_week * 7\n",
    "\n",
    "    print(f\"Current epoch: {context.network_provider.proxy.get_network_status().current_epoch}\")\n",
    "    print(f\"Current week: {current_week}\")\n",
    "    print(f\"Next week at epoch: {next_week_at_epoch}\")\n",
    "\n",
    "    return next_week_at_epoch\n",
    "\n",
    "def advance_to_next_week(contract: FarmContract | StakingContract):\n",
    "    changing_epoch = get_next_week_start_epoch(contract)\n",
    "    current_epoch = context.network_provider.proxy.get_network_status().current_epoch\n",
    "    epochs_to_fast_forward = changing_epoch - current_epoch\n",
    "    logger.info(f\"Fast forwarding to {changing_epoch}\")\n",
    "\n",
    "    if config.CURRENT_ENV.value == \"shadowfork4\":\n",
    "        from contracts.builtin_contracts import SFControlContract\n",
    "        context.deployer_account.sync_nonce(context.network_provider.proxy)\n",
    "        sf_control_contract = SFControlContract(config.SF_CONTROL_ADDRESS)\n",
    "        sf_control_contract.epochs_fast_forward(context.deployer_account, context.network_provider.proxy, epochs_to_fast_forward, 9)\n",
    "\n",
    "    elif config.CURRENT_ENV.value == \"chainsim\":\n",
    "        chain_sim.advance_epochs_to_epoch(changing_epoch)\n",
    "    else:\n",
    "        raise Exception(f\"Unknown environment: {config.CURRENT_ENV.value}\")\n",
    "\n",
    "    while context.network_provider.proxy.get_network_status().current_epoch < changing_epoch:\n",
    "        sleep(6)\n",
    "    logger.info(f\"Fast forwarded to {changing_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "def open_tx_in_explorer(tx_hash: str, open_in_browser: bool = True):\n",
    "    if not open_in_browser:\n",
    "        return\n",
    "\n",
    "    if config.CURRENT_ENV.value == \"chainsim\":\n",
    "        webbrowser.open(f\"https://custom-network.internal-explorer.multiversx.com/transactions/{tx_hash}\")\n",
    "    elif config.CURRENT_ENV.value == \"shadowfork4\":\n",
    "        webbrowser.open(f\"https://testnet-tc-shadowfork-four.internal-explorer.multiversx.com/transactions/{tx_hash}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENARIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain sim control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_sim_stack = start_chain_sim_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_chain_sim_stack(chain_sim_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_upgrade()  # eats 2 blocks\n",
    "\n",
    "staking_upgrade()  # eats 2 blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users_init()\n",
    "user = users[0]\n",
    "print(f\"Using user: {user.address.bech32()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_farm_token_stats(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import chain_simulator_connector\n",
    "user = users_init()[1]\n",
    "user_tk_nonce, user_tk_balance = get_position_for_account(user.address.bech32())\n",
    "metastaking_token_attributes = metastaking_contract.get_decoded_metastake_token_attributes_from_proxy(context.network_provider.proxy, user.address.bech32(), user_tk_nonce)\n",
    "farm_token = ESDTToken(metastaking_contract.farm_token, metastaking_token_attributes['lp_farm_token_nonce'], 0)\n",
    "staking_token = ESDTToken(metastaking_contract.stake_token, metastaking_token_attributes['staking_farm_token_nonce'], 0)\n",
    "\n",
    "# chain_simulator_connector.main([\"--gateway\", context.network_provider.proxy.url, \"--token\", farm_token.get_full_token_name()])\n",
    "# chain_simulator_connector.main([\"--gateway\", context.network_provider.proxy.url, \"--token\", staking_token.get_full_token_name()])\n",
    "print(farm_token.get_full_token_name())\n",
    "print(staking_token.get_full_token_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_in_account = get_all_token_nonces_details_for_account(metastaking_contract.metastake_token, user.address.bech32(), context.network_provider.proxy)\n",
    "print(tokens_in_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_for_user(user)\n",
    "advance_blocks(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = users_init()[0]\n",
    "claim_on_behalf_from_user(user)\n",
    "advance_blocks(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advance_blocks(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim on behalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = users_init()[0]\n",
    "permissions_hub_contract = deploy_permissions_hub()\n",
    "metastaking_contract.set_permissions_hub_address(context.deployer_account, context.network_provider.proxy, permissions_hub_contract.address)\n",
    "advance_blocks(1)\n",
    "\n",
    "claim_on_behalf_from_user(user)\n",
    "advance_blocks(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_in_browser = False\n",
    "\n",
    "for i in range(5):\n",
    "    user_index = i\n",
    "    initial_blocks = 15\n",
    "    in_week_blocks = 10\n",
    "    next_week_blocks = 100*7\n",
    "\n",
    "    def run_scenario():\n",
    "        step = 1\n",
    "        collect_general_test_data(step, collector, user, farm_contract, staking_contract)\n",
    "        collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "        step += 1\n",
    "\n",
    "        logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_1 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}\", claim_ops_1, \"First claim ops\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "        collect_general_test_data(step, collector, user, farm_contract, staking_contract)\n",
    "        collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "        step += 1\n",
    "\n",
    "        advance_blocks(in_week_blocks)\n",
    "        logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_2 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}\", claim_ops_2, \"Second claim ops - same week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "        collect_general_test_data(step, collector, user, farm_contract, staking_contract)\n",
    "        collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "        step += 1\n",
    "\n",
    "        advance_blocks(next_week_blocks)\n",
    "        logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_3 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}\", claim_ops_3, \"Third claim ops - next week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "        collect_general_test_data(step, collector, user, farm_contract, staking_contract)\n",
    "        collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "        step += 1\n",
    "\n",
    "        advance_blocks(in_week_blocks)\n",
    "        logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_4 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}\", claim_ops_4, \"Fourth claim ops - same week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "        collect_general_test_data(step, collector, user, farm_contract, staking_contract)\n",
    "        collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "        step += 1\n",
    "\n",
    "        advance_blocks(next_week_blocks)\n",
    "        logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_5 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}\", claim_ops_5, \"Fifth claim ops - next week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "        \n",
    "        collect_general_test_data(step, collector, user, farm_contract, staking_contract)\n",
    "        collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "        step += 1\n",
    "\n",
    "        advance_blocks(next_week_blocks)\n",
    "        logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_6 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}\", claim_ops_6, \"Sixth claim ops - next week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "        \n",
    "        collect_general_test_data(step, collector, user, farm_contract, staking_contract)\n",
    "        collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "        step += 1\n",
    "\n",
    "        return step\n",
    "\n",
    "    chain_sim, users, collector = init_pre_update_test(initial_blocks)\n",
    "    user = users[user_index]\n",
    "\n",
    "    run_scenario()\n",
    "\n",
    "    ################################################################################\n",
    "    chain_sim, users = init_post_upgrade_test(initial_blocks, chain_sim, collector)\n",
    "    user = users[user_index]\n",
    "\n",
    "    steps = run_scenario()\n",
    "\n",
    "    # close_test(chain_sim, collector, False)\n",
    "\n",
    "    for step in range(2, steps):\n",
    "        compare_transfered_tokens_to_user(collector, user, f\"claim_{step}\")\n",
    "\n",
    "    #raise Exception(\"Stop here\")\n",
    "    collector.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(staking_contract.get_next_week_start_epoch(context.network_provider.proxy))\n",
    "print(context.network_provider.proxy.get_network_status().current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transfered_tokens_to_user(collector, user, \"claim_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collector.collections[\"after\"][\"claim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.contract_data_fetchers import BaseFarmContractDataFetcher\n",
    "\n",
    "print(staking_contract.address)\n",
    "fetcher = BaseFarmContractDataFetcher(WrapperAddress(staking_contract.address), context.network_provider.proxy.url)\n",
    "print(fetcher.get_data(\"getPerSecondRewardAmount\"))\n",
    "\n",
    "print(3000000000000000000 // 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upgrade max apr integrity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount * &max_apr / MAX_PERCENT / BLOCKS_IN_YEAR\n",
    "# division_safety * amount * &max_apr / MAX_PERCENT / SECONDS_IN_YEAR\n",
    "\n",
    "ts_diff = 60\n",
    "farm_supply = staking_contract.get_farm_token_supply(context.network_provider.proxy)\n",
    "division_safety = staking_contract.get_division_safety_constant(context.network_provider.proxy)\n",
    "max_apr = staking_contract.get_max_apr(context.network_provider.proxy)\n",
    "\n",
    "a = farm_supply * max_apr // 10_000 // 31_536_000 // 6\n",
    "b = division_safety * farm_supply * max_apr // 10_000 // 31_536_000\n",
    "\n",
    "a_aggregated = a * (ts_diff // 6)\n",
    "b_aggregated = b * ts_diff // division_safety\n",
    "\n",
    "print(f'old: {a_aggregated}')\n",
    "print(f'new: {b_aggregated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global found_accounts\n",
    "chain_sim, found_accounts = chain_sim_init()\n",
    "\n",
    "collector = PhaseDictsCollector()\n",
    "collector.set_phase(\"before\")\n",
    "\n",
    "users = users_init()\n",
    "advance_blocks(3)\n",
    "consumed_blocks = 3\n",
    "\n",
    "claim_for_user(users[0])\n",
    "advance_blocks(1)\n",
    "sleep(2)\n",
    "collect_general_test_data(0, collector, users[0], farm_contract, staking_contract)\n",
    "collector.add(f\"time_data_{0}\", get_time_data(), \"Time data\")\n",
    "\n",
    "advance_blocks(10)\n",
    "\n",
    "claim_for_user(users[0])\n",
    "advance_blocks(1)\n",
    "sleep(2)\n",
    "collect_general_test_data(1, collector, users[0], farm_contract, staking_contract)\n",
    "collector.add(f\"time_data_{1}\", get_time_data(), \"Time data\")\n",
    "\n",
    "# collector = DictCollector()\n",
    "# collector.set_phase(\"before\")\n",
    "\n",
    "\n",
    "chain_sim.stop()\n",
    "chain_sim_init()\n",
    "\n",
    "collector.set_phase(\"after\")\n",
    "\n",
    "users = users_init()\n",
    "advance_blocks(3)\n",
    "consumed_blocks = 3\n",
    "\n",
    "claim_for_user(users[0])\n",
    "advance_blocks(1)\n",
    "sleep(2)\n",
    "collect_general_test_data(0, collector, users[0], farm_contract, staking_contract)\n",
    "collector.add(f\"time_data_{0}\", get_time_data(), \"Time data\")\n",
    "\n",
    "advance_blocks(10)\n",
    "\n",
    "farm_upgrade(False)  # eats 2 blocks\n",
    "# consumed_blocks += 2\n",
    "staking_upgrade(False)  # eats 2 blocks\n",
    "\n",
    "advance_blocks(1)\n",
    "consumed_blocks += 2\n",
    "\n",
    "collect_general_test_data(1, collector, users[0], farm_contract, staking_contract)\n",
    "collector.add(f\"time_data_{1}\", get_time_data(), \"Time data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report_test_data(collector, True)\n",
    "for i in range(2):\n",
    "    print(collector.collections[\"before\"][f\"FARM_CONTRACT_STATS_{i}\"])\n",
    "    print(collector.collections[\"after\"][f\"FARM_CONTRACT_STATS_{i}\"])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0, _ = collector.collections[\"before\"][\"STAKING_CONTRACT_STATS_0\"][0]\n",
    "data_1, _ = collector.collections[\"before\"][\"STAKING_CONTRACT_STATS_1\"][0]\n",
    "diff_before = data_1.get(\"accumulated_rewards\") - data_0.get(\"accumulated_rewards\")\n",
    "print(f'diff before: {diff_before}')\n",
    "\n",
    "data_0, _ = collector.collections[\"after\"][\"STAKING_CONTRACT_STATS_0\"][0]\n",
    "data_1, _ = collector.collections[\"after\"][\"STAKING_CONTRACT_STATS_1\"][0]\n",
    "diff_after = data_1.get(\"accumulated_rewards\") - data_0.get(\"accumulated_rewards\")\n",
    "print(f'diff after: {diff_after}')\n",
    "print(f'rpb: {diff_after // 11}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "found_ops_before, found_ops_after = get_transfered_tokens_to_user(collector, user, \"claim_2\")\n",
    "pprint(found_ops_before)\n",
    "pprint(found_ops_after)\n",
    "compare_transfered_tokens_to_user(collector, user, f\"claim_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    print(collector.collections[\"before\"][f\"STAKING_CONTRACT_STATS_{i}\"])\n",
    "    print(collector.collections[\"after\"][f\"STAKING_CONTRACT_STATS_{i}\"])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    print(collector.collections[\"before\"][f\"FARM_CONTRACT_STATS_{i}\"])\n",
    "    print(collector.collections[\"after\"][f\"FARM_CONTRACT_STATS_{i}\"])\n",
    "    print(\"-\"*100)\n",
    "#50.39999999999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    print(collector.collections[\"before\"][f\"time_data_{i}\"])\n",
    "    print(collector.collections[\"after\"][f\"time_data_{i}\"])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim compare on multiple users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_in_browser = False\n",
    "\n",
    "initial_blocks = 15\n",
    "in_week_blocks = 10\n",
    "next_week_blocks = 100*7\n",
    "\n",
    "users_to_test = 10\n",
    "\n",
    "def run_scenario():\n",
    "    step = 1\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "    for i in range(users_to_test):\n",
    "        user = users[i]\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_1 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}_{i}\", claim_ops_1, \"First claim ops\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    advance_blocks(in_week_blocks)\n",
    "    logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "    for i in range(users_to_test):\n",
    "        user = users[i]\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_2 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}_{i}\", claim_ops_2, \"Second claim ops - same week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    farm_next_week_start_epoch = farm_contract.get_next_week_start_epoch(context.network_provider.proxy)\n",
    "    staking_next_week_start_epoch = staking_contract.get_next_week_start_epoch(context.network_provider.proxy)\n",
    "    chain_sim.advance_epochs_to_epoch(max(farm_next_week_start_epoch, staking_next_week_start_epoch))\n",
    "    logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "    for i in range(users_to_test):\n",
    "        user = users[i]\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_3 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}_{i}\", claim_ops_3, \"Third claim ops - next week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    farm_next_week_start_epoch = farm_contract.get_next_week_start_epoch(context.network_provider.proxy)\n",
    "    staking_next_week_start_epoch = staking_contract.get_next_week_start_epoch(context.network_provider.proxy)\n",
    "    chain_sim.advance_epochs_to_epoch(max(farm_next_week_start_epoch, staking_next_week_start_epoch))\n",
    "    logger.info(f\"Claiming at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "    for i in range(users_to_test):\n",
    "        user = users[i]\n",
    "        tx_hash = claim_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        claim_ops_4 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"claim_{step}_{i}\", claim_ops_4, \"Fourth claim ops - next week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    return step\n",
    "\n",
    "chain_sim, users, collector = init_pre_update_test(initial_blocks)\n",
    "\n",
    "run_scenario()\n",
    "\n",
    "################################################################################\n",
    "chain_sim, users = init_post_upgrade_test(initial_blocks, chain_sim, collector)\n",
    "\n",
    "steps = run_scenario()\n",
    "\n",
    "# close_test(chain_sim, collector, False)\n",
    "\n",
    "for step in range(2, steps):\n",
    "    for i in range(users_to_test):\n",
    "        compare_transfered_tokens_to_user(collector, users[i], f\"claim_{step}_{i}\")\n",
    "\n",
    "#raise Exception(\"Stop here\")\n",
    "# collector.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exit compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_in_browser = False\n",
    "\n",
    "initial_blocks = 15\n",
    "in_week_blocks = 10\n",
    "next_week_blocks = 100*7\n",
    "\n",
    "users_to_test = 10\n",
    "\n",
    "def run_scenario():\n",
    "    step = 1\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    logger.info(f\"Exiting at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "    for i in range(users_to_test//2):\n",
    "        user = users[i]\n",
    "        tx_hash = exit_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        exit_ops_1 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"exit_{step}_{i}\", exit_ops_1, \"First exit ops\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    farm_next_week_start_epoch = farm_contract.get_next_week_start_epoch(context.network_provider.proxy)\n",
    "    staking_next_week_start_epoch = staking_contract.get_next_week_start_epoch(context.network_provider.proxy)\n",
    "    chain_sim.advance_epochs_to_epoch(max(farm_next_week_start_epoch, staking_next_week_start_epoch))\n",
    "    logger.info(f\"Exiting at block: {context.network_provider.proxy.get_network_status().block_nonce}\")\n",
    "    for i in range(users_to_test//2, users_to_test):\n",
    "        user = users[i]\n",
    "        tx_hash = exit_for_user(user)\n",
    "        advance_blocks(1)\n",
    "        sleep(2)\n",
    "        exit_ops_2 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "        collector.add(f\"exit_{step}_{i}\", exit_ops_2, \"Second exit ops - next week\")\n",
    "        open_tx_in_explorer(tx_hash, show_in_browser)\n",
    "\n",
    "    collect_general_test_data(step, collector, users[0], farm_contract, staking_contract)\n",
    "    collector.add(f\"time_data_{step}\", get_time_data(), \"Time data\")\n",
    "    step += 1\n",
    "\n",
    "    return step\n",
    "\n",
    "chain_sim, users, collector = init_pre_update_test(initial_blocks)\n",
    "\n",
    "run_scenario()\n",
    "\n",
    "################################################################################\n",
    "chain_sim, users = init_post_upgrade_test(initial_blocks, chain_sim, collector)\n",
    "\n",
    "steps = run_scenario()\n",
    "\n",
    "# close_test(chain_sim, collector, False)\n",
    "\n",
    "for step in range(2, steps):\n",
    "    for i in range(users_to_test):\n",
    "        compare_transfered_tokens_to_user(collector, users[i], f\"exit_{step}_{i}\")\n",
    "\n",
    "#raise Exception(\"Stop here\")\n",
    "# collector.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(users_to_test):\n",
    "    print(collector.collections[\"before\"][f\"exit_{3}_{j}\"])\n",
    "    print(collector.collections[\"after\"][f\"exit_{3}_{j}\"])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter farm compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = 0\n",
    "initial_blocks = 15\n",
    "\n",
    "chain_sim, users, collector = init_pre_update_test(initial_blocks)\n",
    "user = users[user_index]\n",
    "\n",
    "collect_general_test_data(0, collector, user, farm_contract, staking_contract)\n",
    "\n",
    "tx_hash = enter_farm_for_user(user)\n",
    "advance_blocks(5)\n",
    "\n",
    "sleep(2)\n",
    "claim_ops_1 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "collect_general_test_data(1, collector, user, farm_contract, staking_contract)\n",
    "collector.add(DictType.OP1, claim_ops_1, \"Initial enter ops\")\n",
    "\n",
    "################################################################################\n",
    "chain_sim, users, permissions_hub_contract, dummy_proxy_contract = init_post_upgrade_test(initial_blocks, chain_sim, collector)\n",
    "user = users[user_index]\n",
    "\n",
    "collect_general_test_data(0, collector, user, farm_contract, staking_contract)\n",
    "\n",
    "tx_hash = enter_farm_for_user(user)\n",
    "advance_blocks(5)\n",
    "\n",
    "sleep(2)\n",
    "claim_ops_3 = context.network_provider.get_tx_operations(tx_hash, True)\n",
    "collect_general_test_data(1, collector, user, farm_contract, staking_contract)\n",
    "collector.add(DictType.OP1, claim_ops_3, \"Ending enter ops\")\n",
    "\n",
    "close_test(chain_sim, collector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
